{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LC8LGG5SXgcc",
    "outputId": "91ab0f8d-5600-4ee7-8437-ed2065531d36"
   },
   "outputs": [],
   "source": [
    "# !pip install neo4j google-generativeai langchain-google-genai langchain-community faiss-cpu python-dotenv sentence-transformers\n",
    "\n",
    "\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4poGE07GXgce"
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Neo4j connection setup from environment variables\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PxDFMSFFXgce"
   },
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ImuMDUKFXgce"
   },
   "outputs": [],
   "source": [
    "def get_schema():\n",
    "    with driver.session() as session:\n",
    "        # Get node labels\n",
    "        labels_query = \"\"\"\n",
    "        CALL db.labels() YIELD label\n",
    "        RETURN collect(label) as labels\n",
    "        \"\"\"\n",
    "        result = session.run(labels_query).single()\n",
    "        labels = result['labels'] if result else []\n",
    "\n",
    "        # Get relationship types\n",
    "        rels_query = \"\"\"\n",
    "        CALL db.relationshipTypes() YIELD relationshipType\n",
    "        RETURN collect(relationshipType) as relationships\n",
    "        \"\"\"\n",
    "        result = session.run(rels_query).single()\n",
    "        relationships = result['relationships'] if result else []\n",
    "\n",
    "        # Get properties for each node label\n",
    "        schema = {}\n",
    "        for label in labels:\n",
    "            props_query = f\"\"\"\n",
    "            MATCH (n:{label})\n",
    "            RETURN distinct keys(n) as properties\n",
    "            LIMIT 1\n",
    "            \"\"\"\n",
    "            result = session.run(props_query).single()\n",
    "            properties = result['properties'] if result else []\n",
    "            schema[label] = properties\n",
    "\n",
    "        return {\n",
    "            'node_labels': labels,\n",
    "            'relationships': relationships,\n",
    "            'node_properties': schema\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "C_ci7gI3Xgcf"
   },
   "outputs": [],
   "source": [
    "def extract_knowledge_base():\n",
    "    with driver.session() as session:\n",
    "        # Extract nodes and relationships as text\n",
    "        query = \"\"\"\n",
    "        MATCH (n)\n",
    "        OPTIONAL MATCH (n)-[r]->(m)\n",
    "        RETURN n, r, m\n",
    "        \"\"\"\n",
    "        results = session.run(query)\n",
    "\n",
    "        # Convert to text chunks\n",
    "        text_chunks = []\n",
    "        for record in results:\n",
    "            node1 = record['n']\n",
    "            rel = record['r']\n",
    "            node2 = record['m']\n",
    "\n",
    "            if rel and node2:\n",
    "                chunk = f\"{dict(node1)} is {rel.type} {dict(node2)}\"\n",
    "            else:\n",
    "                chunk = f\"Node: {dict(node1)}\"\n",
    "            text_chunks.append(chunk)\n",
    "\n",
    "        return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1S6Ii2DZXgcf"
   },
   "outputs": [],
   "source": [
    "# Initialize Gemini\n",
    "# GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "# genai.configure(api_key=GOOGLE_API_KEY)\n",
    "os.environ[\"GOOGLE_API_KEY\"] =GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jirHvre4Xgcf"
   },
   "outputs": [],
   "source": [
    "# Create embeddings and vector store\n",
    "def create_vector_store(text_chunks):\n",
    "    # Using 'all-MiniLM-L6-v2' - a lightweight but effective model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'}\n",
    "    )\n",
    "    # better model (but slightly slower)\n",
    "\n",
    "    # embeddings = HuggingFaceEmbeddings(\n",
    "    #     model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    #     model_kwargs={'device': 'cpu'}\n",
    "    # )\n",
    "\n",
    "    # a smaller, faster model:\n",
    "\n",
    "    # embeddings = HuggingFaceEmbeddings(\n",
    "    #     model_name=\"sentence-transformers/paraphrase-MiniLM-L3-v2\",\n",
    "    #     model_kwargs={'device': 'cpu'}\n",
    "    # )\n",
    "\n",
    "    vector_store = FAISS.from_texts(text_chunks, embeddings)\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7ED7OBmMXgcf"
   },
   "outputs": [],
   "source": [
    "# Setup RAG with Gemini\n",
    "def setup_rag(vector_store):\n",
    "    # llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY)\n",
    "    llm = GoogleGenerativeAI(model=\"gemini-pro\",)\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_store.as_retriever()\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzmovXa7Xgcg",
    "outputId": "8f2b7414-8ae8-4af8-e5e8-95014a7d78f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_labels': ['User', 'Project', 'Tag', 'Entity'],\n",
       " 'relationships': ['OWNS', 'TAGGED_WITH', 'FRIEND', 'STARRED', 'HAS_SKILL'],\n",
       " 'node_properties': {'User': ['password',\n",
       "   'email',\n",
       "   'username',\n",
       "   'bio',\n",
       "   'github_username',\n",
       "   'name',\n",
       "   'leetcode_username',\n",
       "   'profile_image',\n",
       "   'skillset',\n",
       "   'suggestions'],\n",
       "  'Project': ['repo_link', 'description', 'title'],\n",
       "  'Tag': ['name'],\n",
       "  'Entity': []}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main functions\n",
    "\n",
    "schema = get_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-k-6iwO7Xgch"
   },
   "outputs": [],
   "source": [
    "# Extract knowledge base\n",
    "text_chunks = extract_knowledge_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3GkpoIQXgch",
    "outputId": "4ce9d681-b49f-4b56-f22d-e1e7a5b7b5b8"
   },
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "vector_store = create_vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bieNilA7Xgch"
   },
   "outputs": [],
   "source": [
    "# Setup RAG\n",
    "qa_chain = setup_rag(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "w-_aKngnXgch"
   },
   "outputs": [],
   "source": [
    "# Create system prompt with schema context\n",
    "schema_context = f\"Database Schema: {schema}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiw7bG84Xgch",
    "outputId": "9d42e2af-4c3e-4436-d78d-e5733b99aa8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepraj\\AppData\\Local\\Temp\\ipykernel_2040\\2529303531.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  response = qa_chain.run(schema_context + query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database schema is as follows:\n",
      "\n",
      "* **Node labels:** User, Project, Tag, Entity\n",
      "* **Relationships:** OWNS, TAGGED_WITH, FRIEND, STARRED, HAS_SKILL\n",
      "* **Node properties:**\n",
      "    * User: password, email, username, bio, github_username, name, leetcode_username, profile_image, skillset, suggestions\n",
      "    * Project: repo_link, description, title\n",
      "    * Tag: name\n",
      "    * Entity: []\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Tell me about the database\"\n",
    "# query = \"give me some data from the dataabase\"\n",
    "response = qa_chain.run(schema_context + query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDf8MKB9Xgch"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
